{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonModelParser:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = self.load_json_file()\n",
    "        self.parse_model_data()\n",
    "\n",
    "    def printDetails(self):\n",
    "        print(\"\\tINPUT SIZE:\",self.input_size)\n",
    "        print(\"\\tLAYERS:\", self.layers)\n",
    "        print(\"\\tINPUT:\", self.input)\n",
    "        print(\"\\tINITIAL WEIGHTS:\", self.initial_weights)\n",
    "        print(\"\\tTARGET:\", self.target)\n",
    "        print(\"\\tLEARNING RATE:\", self.learning_rate)\n",
    "        print(\"\\tBATCH SIZE:\", self.batch_size)\n",
    "        print(\"\\tMAX ITERATION:\", self.max_iteration)\n",
    "        print(\"\\tERROR THRESHOLD:\", self.error_threshold)\n",
    "    \n",
    "\n",
    "    def load_json_file(self):\n",
    "        try:\n",
    "            with open(self.filepath, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"The file {self.filepath} was not found\")\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from the file {self.filepath}\")\n",
    "            return None\n",
    "\n",
    "    def parse_model_data(self):\n",
    "        if self.data:\n",
    "            self.case = self.data.get('case', {})\n",
    "            self.model = self.case.get('model', {})\n",
    "            self.input_size = self.model.get('input_size')\n",
    "\n",
    "            raw_layers = self.model.get('layers', [])   \n",
    "            self.layers = [{'number_of_neurons': layer.get('number_of_neurons'),\n",
    "                        'activation_function': layer.get('activation_function')}\n",
    "                       for layer in raw_layers]\n",
    "            \n",
    "            self.input = self.case.get('input', [])\n",
    "            print(self.case.get(\"initial_weights\"))\n",
    "            self.initial_weights = self.case.get('initial_weights', [])\n",
    "            self.target = self.case.get('target', [])\n",
    "            self.parameters = self.case.get('learning_parameters', {})\n",
    "\n",
    "            self.learning_rate = self.parameters.get('learning_rate')\n",
    "            self.batch_size = self.parameters.get('batch_size')\n",
    "            self.max_iteration = self.parameters.get('max_iteration')\n",
    "            self.error_threshold = self.parameters.get('error_threshold')\n",
    "\n",
    "            self.expect = self.data.get('expect', {})\n",
    "            self.stopped_by = self.expect.get('stopped_by', '')\n",
    "            self.final_weights = self.expect.get('final_weights', [])\n",
    "\n",
    "    @staticmethod\n",
    "    def save_json_file(data, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        except IOError:\n",
    "            print(f\"Could not save data to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TensorFlowModel: \n",
    "    def __init__(self, inputs, targets, learning_rate, batch_size, initial_weights, layers) -> None:\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = len(inputs[0])\n",
    "        self.initial_weights = initial_weights\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.inputs, self.targets))\n",
    "        self.dataset = self.dataset.batch(batch_size)\n",
    "        self.model = tf.keras.Sequential()\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            if i == 0:\n",
    "                self.model.add(tf.keras.layers.Dense(\n",
    "                    layer['number_of_neurons'],\n",
    "                    activation=layer['activation_function'],\n",
    "                    input_shape=(self.input_size,),\n",
    "                    kernel_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][1:])(shape, dtype=dtype),\n",
    "                    bias_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][0])(shape, dtype=dtype)\n",
    "                ))\n",
    "            else:\n",
    "                self.model.add(tf.keras.layers.Dense(\n",
    "                    layer['number_of_neurons'],\n",
    "                    activation=layer['activation_function'],\n",
    "                    kernel_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][1:])(shape, dtype=dtype),\n",
    "                    bias_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][0])(shape, dtype=dtype)\n",
    "                ))\n",
    "        \n",
    "        loss_function = tf.keras.losses.CategoricalCrossentropy() if layers[-1]['activation_function'] == 'softmax' else tf.keras.losses.MeanSquaredError()\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "    def fit_model(self, max_epochs, error_threshold):\n",
    "        class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, _, logs = None):\n",
    "                if(logs.get(\"loss\") < error_threshold):\n",
    "                    self.model.stop_training = True\n",
    "        thressholdCallback = ThresholdCallback()\n",
    "        self.model.fit(self.dataset, epochs=max_epochs, callbacks=[thressholdCallback])\n",
    "\n",
    "    def show_prediction(self):\n",
    "        print(\"============================= Result =============================\\n\")\n",
    "        if(self.model.stop_training):\n",
    "            print(f\"Stopped by : error_threshold\\n\")\n",
    "        else:\n",
    "            print(\"Stopped by : max_iteration\\n\")\n",
    "        for i,layer in enumerate(self.model.layers):\n",
    "            weights, biases = layer.get_weights()\n",
    "            print(f\"Layer-{i}\")\n",
    "            print(f\"Weights : {weights}\\n\")\n",
    "            print(f\"Biases : {biases}\\n\")\n",
    "        print(\"==================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1, 0.9, -0.1], [-0.2, 0.8, 0.2], [0.3, -0.7, 0.3], [0.4, 0.6, -0.4], [0.5, 0.5, 0.5], [-0.6, 0.4, 0.6], [-0.7, -0.3, 0.7], [0.8, 0.2, -0.8], [0.9, -0.1, 0.0]]]\n",
      "ini inputs :  [[-2.4, -2.78, -0.6, 0.37, 2.46, -0.92, 2.76, 2.62], [-1.79, 1.65, -0.77, -1.03, 0.1, 2.12, -2.36, 1.25], [1.65, 2.34, 0.27, 2.34, 0.52, 1.37, 1.77, 0.62]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 2.5703  \n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 2.1917\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 1.8861\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 1.6386\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 1.4317\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 1.2526\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 1.0935\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.9503\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.8212\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7083 - loss: 0.7057\n",
      "============================= Result =============================\n",
      "\n",
      "Stopped by : max_iteration\n",
      "\n",
      "Layer-0\n",
      "Weights : [[-0.33551654  0.67700493  0.45851156]\n",
      " [ 0.4831443  -0.8524122   0.26926786]\n",
      " [ 0.34002548  0.5723754  -0.31240082]\n",
      " [ 0.31397712  0.4634974   0.7225255 ]\n",
      " [-0.6965244   0.47891894  0.6176055 ]\n",
      " [-0.50884515 -0.36354133  0.57238674]\n",
      " [ 0.4189131   0.26354513 -0.48245814]\n",
      " [ 0.90374154 -0.01759502 -0.08614664]]\n",
      "\n",
      "Biases : [ 0.12674606  0.9149538  -0.14169984]\n",
      "\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    currDir = os.getcwd()\n",
    "    testDir = currDir.replace(\"src\",\"test\")\n",
    "    file = os.path.join(testDir, \"softmax.json\")\n",
    "    json_file = JsonModelParser(file)\n",
    "    inputs = json_file.input\n",
    "    print(\"ini inputs : \", inputs)\n",
    "    targets = json_file.target\n",
    "    learning_rate = json_file.learning_rate\n",
    "    layers = json_file.layers\n",
    "    batch_size = json_file.batch_size\n",
    "    initial_weights = json_file.initial_weights\n",
    "    max_iter = json_file.max_iteration\n",
    "    error_threshold = json_file.error_threshold\n",
    "    model = TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n",
    "    model.fit_model(max_iter, error_threshold)\n",
    "    model.show_prediction()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Outputs:\n",
      "[[ 1.7         2.1         0.90000004]\n",
      " [ 1.9000001   1.7        -0.19999993]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the inputs and targets\n",
    "inputs = tf.constant([\n",
    "    [3.0, 1.0],\n",
    "    [1.0, 2.0]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "targets = tf.constant([\n",
    "    [2.0, 0.3, -1.9],\n",
    "    [1.3, -0.7, 0.1]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Number of neurons, activation, and learning rate\n",
    "number_of_neurons = 3\n",
    "activation = \"linear\"\n",
    "learning_rate = 0.1\n",
    "batch_size = 2  # as you mentioned, batch_size of 2\n",
    "\n",
    "# Initial weights and new uniform bias of 1\n",
    "initial_weights = [\n",
    "    [0.1, 0.3, 0.2],  # weights for inputs to neuron 1\n",
    "    [0.4, 0.2, -0.7]  # weights for inputs to neuron 2\n",
    "]\n",
    "initial_bias = [1.0, 1.0, 1.0]  # uniform bias for all neurons\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(number_of_neurons, activation=activation, input_shape=(2,), use_bias=True)\n",
    "])\n",
    "\n",
    "# Set the initial weights and bias\n",
    "model.layers[0].set_weights([tf.constant(initial_weights, dtype=tf.float32), tf.constant(initial_bias, dtype=tf.float32)])\n",
    "\n",
    "# Compile the model with the specified optimizer and learning rate\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Since this is a simple forward pass, we'll use predict instead of fit to demonstrate batching\n",
    "outputs = model.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "print(\"Outputs:\")\n",
    "print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
