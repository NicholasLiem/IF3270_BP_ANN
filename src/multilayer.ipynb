{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonModelParser:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = self.load_json_file()\n",
    "        self.parse_model_data()\n",
    "\n",
    "    def printDetails(self):\n",
    "        print(\"\\tINPUT SIZE:\",self.input_size)\n",
    "        print(\"\\tLAYERS:\", self.layers)\n",
    "        print(\"\\tINPUT:\", self.input)\n",
    "        print(\"\\tINITIAL WEIGHTS:\", self.initial_weights)\n",
    "        print(\"\\tTARGET:\", self.target)\n",
    "        print(\"\\tLEARNING RATE:\", self.learning_rate)\n",
    "        print(\"\\tBATCH SIZE:\", self.batch_size)\n",
    "        print(\"\\tMAX ITERATION:\", self.max_iteration)\n",
    "        print(\"\\tERROR THRESHOLD:\", self.error_threshold)\n",
    "    \n",
    "\n",
    "    def load_json_file(self):\n",
    "        try:\n",
    "            with open(self.filepath, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"The file {self.filepath} was not found\")\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from the file {self.filepath}\")\n",
    "            return None\n",
    "\n",
    "    def parse_model_data(self):\n",
    "        if self.data:\n",
    "            self.case = self.data.get('case', {})\n",
    "            self.model = self.case.get('model', {})\n",
    "            self.input_size = self.model.get('input_size')\n",
    "\n",
    "            raw_layers = self.model.get('layers', [])   \n",
    "            self.layers = [{'number_of_neurons': layer.get('number_of_neurons'),\n",
    "                        'activation_function': layer.get('activation_function')}\n",
    "                       for layer in raw_layers]\n",
    "            \n",
    "            self.input = self.case.get('input', [])\n",
    "            print(self.case.get(\"initial_weights\"))\n",
    "            self.initial_weights = self.case.get('initial_weights', [])\n",
    "            self.target = self.case.get('target', [])\n",
    "            self.parameters = self.case.get('learning_parameters', {})\n",
    "\n",
    "            self.learning_rate = self.parameters.get('learning_rate')\n",
    "            self.batch_size = self.parameters.get('batch_size')\n",
    "            self.max_iteration = self.parameters.get('max_iteration')\n",
    "            self.error_threshold = self.parameters.get('error_threshold')\n",
    "\n",
    "            self.expect = self.data.get('expect', {})\n",
    "            self.stopped_by = self.expect.get('stopped_by', '')\n",
    "            self.final_weights = self.expect.get('final_weights', [])\n",
    "\n",
    "    @staticmethod\n",
    "    def save_json_file(data, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        except IOError:\n",
    "            print(f\"Could not save data to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class TensorFlowModel: \n",
    "    def __init__(self, inputs, targets, learning_rate, batch_size, initial_weights, layers) -> None:\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = len(inputs[0])\n",
    "        self.initial_weights = initial_weights\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.inputs, self.targets))\n",
    "        self.dataset = self.dataset.batch(batch_size)\n",
    "        self.model = tf.keras.Sequential()\n",
    "        \n",
    "        for i, layer in enumerate(layers):\n",
    "            if i == 0:\n",
    "                self.model.add(tf.keras.layers.Dense(\n",
    "                    layer['number_of_neurons'],\n",
    "                    activation=layer['activation_function'],\n",
    "                    input_shape=(self.input_size,),\n",
    "                    kernel_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][1:])(shape, dtype=dtype),\n",
    "                    bias_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][0])(shape, dtype=dtype)\n",
    "                ))\n",
    "            else:\n",
    "                self.model.add(tf.keras.layers.Dense(\n",
    "                    layer['number_of_neurons'],\n",
    "                    activation=layer['activation_function'],\n",
    "                    kernel_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][1:])(shape, dtype=dtype),\n",
    "                    bias_initializer=lambda shape, dtype: tf.constant_initializer(initial_weights[i][0])(shape, dtype=dtype)\n",
    "                ))\n",
    "        \n",
    "        loss_function = tf.keras.losses.CategoricalCrossentropy() if layers[-1]['activation_function'] == 'softmax' else tf.keras.losses.MeanSquaredError()\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "    def fit_model(self, max_epochs, error_threshold):\n",
    "        class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, _, logs = None):\n",
    "                if(logs.get(\"loss\") < error_threshold):\n",
    "                    self.model.stop_training = True\n",
    "        thressholdCallback = ThresholdCallback()\n",
    "        self.model.fit(self.dataset, epochs=max_epochs, callbacks=[thressholdCallback])\n",
    "    def predict(self, new_input):\n",
    "        # Ensure that new_input is in the correct shape (batch_size, input_size)\n",
    "        new_input = np.array(new_input).reshape(1, -1)  # Reshape if one sample\n",
    "        predictions = self.model.predict(new_input)\n",
    "        return predictions\n",
    "    \n",
    "    def show_prediction(self):\n",
    "        total_weights = []\n",
    "        total_biases = []\n",
    "        print(\"============================= Result =============================\\n\")\n",
    "        if(self.model.stop_training):\n",
    "            print(f\"Stopped by : error_threshold\\n\")\n",
    "        else:\n",
    "            print(\"Stopped by : max_iteration\\n\")\n",
    "        for i,layer in enumerate(self.model.layers):\n",
    "            print(layer.get_weights())\n",
    "            weights, biases = layer.get_weights()\n",
    "            total_weights.append(weights)\n",
    "            total_biases.append(biases)\n",
    "            print(f\"Layer-{i}\")\n",
    "            print(f\"Weights : {weights}\\n\")\n",
    "            print(f\"Biases : {biases}\\n\")\n",
    "        print(\"==================================================================\")\n",
    "        return total_weights, total_biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.2, 0.2, 1.0], [0.3, 0.5, 0.5], [-0.5, -1.0, 0.5]]]\n",
      "ini inputs :  [[1.0, 0.8], [-0.3, -1.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.0000e+00 - loss: 0.9312\n",
      "============================= Result =============================\n",
      "\n",
      "Stopped by : max_iteration\n",
      "\n",
      "[array([[ 0.30110002,  0.5095    ,  0.4335    ],\n",
      "       [-0.49633333, -0.9683333 ,  0.43033332]], dtype=float32), array([-0.20366667,  0.16833334,  0.96166664], dtype=float32)]\n",
      "Layer-0\n",
      "Weights : [[ 0.30110002  0.5095      0.4335    ]\n",
      " [-0.49633333 -0.9683333   0.43033332]]\n",
      "\n",
      "Biases : [-0.20366667  0.16833334  0.96166664]\n",
      "\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    currDir = os.getcwd()\n",
    "    testDir = currDir.replace(\"src\",\"test\")\n",
    "    file = os.path.join(testDir, \"relu_b.json\")\n",
    "    json_file = JsonModelParser(file)\n",
    "    inputs = json_file.input\n",
    "    print(\"ini inputs : \", inputs)\n",
    "    targets = json_file.target\n",
    "    learning_rate = json_file.learning_rate\n",
    "    layers = json_file.layers\n",
    "    batch_size = json_file.batch_size\n",
    "    initial_weights = json_file.initial_weights\n",
    "    max_iter = json_file.max_iteration\n",
    "    error_threshold = json_file.error_threshold\n",
    "    model = TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n",
    "    model.fit_model(max_iter, error_threshold)\n",
    "    model.show_prediction()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1, 0.3, 0.2], [0.4, 0.2, -0.7], [0.1, -0.8, 0.5], [0.1, 0.3, 0.2], [0.4, 0.2, -0.7]]]\n",
      "ini inputs :  [[5.1, 3.5, 1.4, 0.2], [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5.0, 3.6, 1.4, 0.2], [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5.0, 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3.0, 1.4, 0.1], [4.3, 3.0, 1.1, 0.1], [5.8, 4.0, 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], [5.1, 3.5, 1.4, 0.3], [5.7, 3.8, 1.7, 0.3], [5.1, 3.8, 1.5, 0.3], [5.4, 3.4, 1.7, 0.2], [5.1, 3.7, 1.5, 0.4], [4.6, 3.6, 1.0, 0.2], [5.1, 3.3, 1.7, 0.5], [4.8, 3.4, 1.9, 0.2], [5.0, 3.0, 1.6, 0.2], [5.0, 3.4, 1.6, 0.4], [5.2, 3.5, 1.5, 0.2], [5.2, 3.4, 1.4, 0.2], [4.7, 3.2, 1.6, 0.2], [4.8, 3.1, 1.6, 0.2], [5.4, 3.4, 1.5, 0.4], [5.2, 4.1, 1.5, 0.1], [5.5, 4.2, 1.4, 0.2], [4.9, 3.1, 1.5, 0.1], [5.0, 3.2, 1.2, 0.2], [5.5, 3.5, 1.3, 0.2], [4.9, 3.1, 1.5, 0.1], [4.4, 3.0, 1.3, 0.2], [5.1, 3.4, 1.5, 0.2], [5.0, 3.5, 1.3, 0.3], [4.5, 2.3, 1.3, 0.3], [4.4, 3.2, 1.3, 0.2], [5.0, 3.5, 1.6, 0.6], [5.1, 3.8, 1.9, 0.4], [4.8, 3.0, 1.4, 0.3], [5.1, 3.8, 1.6, 0.2], [4.6, 3.2, 1.4, 0.2], [5.3, 3.7, 1.5, 0.2], [5.0, 3.3, 1.4, 0.2], [7.0, 3.2, 4.7, 1.4], [6.4, 3.2, 4.5, 1.5], [6.9, 3.1, 4.9, 1.5], [5.5, 2.3, 4.0, 1.3], [6.5, 2.8, 4.6, 1.5], [5.7, 2.8, 4.5, 1.3], [6.3, 3.3, 4.7, 1.6], [4.9, 2.4, 3.3, 1.0], [6.6, 2.9, 4.6, 1.3], [5.2, 2.7, 3.9, 1.4], [5.0, 2.0, 3.5, 1.0], [5.9, 3.0, 4.2, 1.5], [6.0, 2.2, 4.0, 1.0], [6.1, 2.9, 4.7, 1.4], [5.6, 2.9, 3.6, 1.3], [6.7, 3.1, 4.4, 1.4], [5.6, 3.0, 4.5, 1.5], [5.8, 2.7, 4.1, 1.0], [6.2, 2.2, 4.5, 1.5], [5.6, 2.5, 3.9, 1.1], [5.9, 3.2, 4.8, 1.8], [6.1, 2.8, 4.0, 1.3], [6.3, 2.5, 4.9, 1.5], [6.1, 2.8, 4.7, 1.2], [6.4, 2.9, 4.3, 1.3], [6.6, 3.0, 4.4, 1.4], [6.8, 2.8, 4.8, 1.4], [6.7, 3.0, 5.0, 1.7], [6.0, 2.9, 4.5, 1.5], [5.7, 2.6, 3.5, 1.0], [5.5, 2.4, 3.8, 1.1], [5.5, 2.4, 3.7, 1.0], [5.8, 2.7, 3.9, 1.2], [6.0, 2.7, 5.1, 1.6], [5.4, 3.0, 4.5, 1.5], [6.0, 3.4, 4.5, 1.6], [6.7, 3.1, 4.7, 1.5], [6.3, 2.3, 4.4, 1.3], [5.6, 3.0, 4.1, 1.3], [5.5, 2.5, 4.0, 1.3], [5.5, 2.6, 4.4, 1.2], [6.1, 3.0, 4.6, 1.4], [5.8, 2.6, 4.0, 1.2], [5.0, 2.3, 3.3, 1.0], [5.6, 2.7, 4.2, 1.3], [5.7, 3.0, 4.2, 1.2], [5.7, 2.9, 4.2, 1.3], [6.2, 2.9, 4.3, 1.3], [5.1, 2.5, 3.0, 1.1], [5.7, 2.8, 4.1, 1.3], [6.3, 3.3, 6.0, 2.5], [5.8, 2.7, 5.1, 1.9], [7.1, 3.0, 5.9, 2.1], [6.3, 2.9, 5.6, 1.8], [6.5, 3.0, 5.8, 2.2], [7.6, 3.0, 6.6, 2.1], [4.9, 2.5, 4.5, 1.7], [7.3, 2.9, 6.3, 1.8], [6.7, 2.5, 5.8, 1.8], [7.2, 3.6, 6.1, 2.5], [6.5, 3.2, 5.1, 2.0], [6.4, 2.7, 5.3, 1.9], [6.8, 3.0, 5.5, 2.1], [5.7, 2.5, 5.0, 2.0], [5.8, 2.8, 5.1, 2.4], [6.4, 3.2, 5.3, 2.3], [6.5, 3.0, 5.5, 1.8], [7.7, 3.8, 6.7, 2.2], [7.7, 2.6, 6.9, 2.3], [6.0, 2.2, 5.0, 1.5], [6.9, 3.2, 5.7, 2.3], [5.6, 2.8, 4.9, 2.0], [7.7, 2.8, 6.7, 2.0], [6.3, 2.7, 4.9, 1.8], [6.7, 3.3, 5.7, 2.1], [7.2, 3.2, 6.0, 1.8], [6.2, 2.8, 4.8, 1.8], [6.1, 3.0, 4.9, 1.8], [6.4, 2.8, 5.6, 2.1], [7.2, 3.0, 5.8, 1.6], [7.4, 2.8, 6.1, 1.9], [7.9, 3.8, 6.4, 2.0], [6.4, 2.8, 5.6, 2.2], [6.3, 2.8, 5.1, 1.5], [6.1, 2.6, 5.6, 1.4], [7.7, 3.0, 6.1, 2.3], [6.3, 3.4, 5.6, 2.4], [6.4, 3.1, 5.5, 1.8], [6.0, 3.0, 4.8, 1.8], [6.9, 3.1, 5.4, 2.1], [6.7, 3.1, 5.6, 2.4], [6.9, 3.1, 5.1, 2.3], [5.8, 2.7, 5.1, 1.9], [6.8, 3.2, 5.9, 2.3], [6.7, 3.3, 5.7, 2.5], [6.7, 3.0, 5.2, 2.3], [6.3, 2.5, 5.0, 1.9], [6.5, 3.0, 5.2, 2.0], [6.2, 3.4, 5.4, 2.3], [5.9, 3.0, 5.1, 1.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7264 - loss: 1.4353 \n",
      "============================= Result =============================\n",
      "\n",
      "Stopped by : max_iteration\n",
      "\n",
      "[array([[ 0.05775671,  0.14111806, -0.38728544],\n",
      "       [-0.08108397, -0.8101177 ,  0.661761  ],\n",
      "       [-0.11003511,  0.21955857,  0.39927277],\n",
      "       [ 0.33552825,  0.16913599, -0.6366245 ]], dtype=float32), array([0.04086624, 0.29377073, 0.25311777], dtype=float32)]\n",
      "Layer-0\n",
      "Weights : [[ 0.05775671  0.14111806 -0.38728544]\n",
      " [-0.08108397 -0.8101177   0.661761  ]\n",
      " [-0.11003511  0.21955857  0.39927277]\n",
      " [ 0.33552825  0.16913599 -0.6366245 ]]\n",
      "\n",
      "Biases : [0.04086624 0.29377073 0.25311777]\n",
      "\n",
      "==================================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Ini predictions : [[-0.0353119 -1.4807298  1.0257825]]\n",
      "Ini weights : [array([[ 0.05775671,  0.14111806, -0.38728544],\n",
      "       [-0.08108397, -0.8101177 ,  0.661761  ],\n",
      "       [-0.11003511,  0.21955857,  0.39927277],\n",
      "       [ 0.33552825,  0.16913599, -0.6366245 ]], dtype=float32)]\n",
      " Ini biases : [array([0.04086624, 0.29377073, 0.25311777], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def main():\n",
    "    currDir = os.getcwd()\n",
    "    file = os.path.join(currDir, \"model_data.json\")\n",
    "    json_file = JsonModelParser(file)\n",
    "    inputs = json_file.input\n",
    "    print(\"ini inputs : \", inputs)\n",
    "    targets = json_file.target\n",
    "    learning_rate = json_file.learning_rate\n",
    "    layers = json_file.layers\n",
    "    batch_size = json_file.batch_size\n",
    "    initial_weights = json_file.initial_weights\n",
    "    max_iter = json_file.max_iteration\n",
    "    error_threshold = json_file.error_threshold\n",
    "    model = TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n",
    "    model.fit_model(max_iter, error_threshold)\n",
    "    weights, biases = model.show_prediction()\n",
    "\n",
    "    with open(\"iris.csv\",\"r\") as csvfile : \n",
    "        datareader = csv.DictReader(csvfile)\n",
    "        for row in datareader : \n",
    "            current = [\n",
    "                float(row[\"SepalLengthCm\"]),\n",
    "                float(row[\"SepalWidthCm\"]),\n",
    "                float(row[\"PetalLengthCm\"]),\n",
    "                float(row[\"PetalWidthCm\"])\n",
    "            ]\n",
    "            species = row[\"Species\"]\n",
    "            predictions = model.predict(current)\n",
    "            print(\"Ini predictions :\", predictions)\n",
    "            break\n",
    "    print(f\"Ini weights : {weights}\\n Ini biases : {biases}\")\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
