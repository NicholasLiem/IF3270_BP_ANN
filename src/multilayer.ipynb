{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonModelParser:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = self.load_json_file()\n",
    "        self.parse_model_data()\n",
    "\n",
    "    def printDetails(self):\n",
    "        print(\"\\tINPUT SIZE:\",self.input_size)\n",
    "        print(\"\\tLAYERS:\", self.layers)\n",
    "        print(\"\\tINPUT:\", self.input)\n",
    "        print(\"\\tINITIAL WEIGHTS:\", self.initial_weights)\n",
    "        print(\"\\tTARGET:\", self.target)\n",
    "        print(\"\\tLEARNING RATE:\", self.learning_rate)\n",
    "        print(\"\\tBATCH SIZE:\", self.batch_size)\n",
    "        print(\"\\tMAX ITERATION:\", self.max_iteration)\n",
    "        print(\"\\tERROR THRESHOLD:\", self.error_threshold)\n",
    "    \n",
    "\n",
    "    def load_json_file(self):\n",
    "        try:\n",
    "            with open(self.filepath, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"The file {self.filepath} was not found\")\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from the file {self.filepath}\")\n",
    "            return None\n",
    "\n",
    "    def parse_model_data(self):\n",
    "        if self.data:\n",
    "            self.case = self.data.get('case', {})\n",
    "            self.model = self.case.get('model', {})\n",
    "            self.input_size = self.model.get('input_size')\n",
    "\n",
    "            raw_layers = self.model.get('layers', [])   \n",
    "            self.layers = [{'number_of_neurons': layer.get('number_of_neurons'),\n",
    "                        'activation_function': layer.get('activation_function')}\n",
    "                       for layer in raw_layers]\n",
    "            \n",
    "            self.input = self.case.get('input', [])\n",
    "            print(self.case.get(\"initial_weights\"))\n",
    "            self.initial_weights = self.case.get('initial_weights', [])\n",
    "            self.target = self.case.get('target', [])\n",
    "            self.parameters = self.case.get('learning_parameters', {})\n",
    "\n",
    "            self.learning_rate = self.parameters.get('learning_rate')\n",
    "            self.batch_size = self.parameters.get('batch_size')\n",
    "            self.max_iteration = self.parameters.get('max_iteration')\n",
    "            self.error_threshold = self.parameters.get('error_threshold')\n",
    "\n",
    "            self.expect = self.data.get('expect', {})\n",
    "            self.stopped_by = self.expect.get('stopped_by', '')\n",
    "            self.final_weights = self.expect.get('final_weights', [])\n",
    "\n",
    "    @staticmethod\n",
    "    def save_json_file(data, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        except IOError:\n",
    "            print(f\"Could not save data to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TensorFlowModel: \n",
    "    def __init__(self, inputs, targets, learning_rate, batch_size, initial_weights, layers) -> None:\n",
    "        self.inputs = tf.constant(inputs, dtype=tf.float32)\n",
    "        self.targets = tf.constant(targets, dtype=tf.float32)\n",
    "        self.initial_weights = tf.constant(initial_weights, dtype=tf.float32)\n",
    "        self.input_size = len(inputs[0])\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.inputs, self.targets))\n",
    "        self.dataset = self.dataset.batch(batch_size)\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for i in range(len(layers)):\n",
    "            current_layer = layers[i]\n",
    "            current_number_of_neurons = current_layer[\"number_of_neurons\"]\n",
    "            current_activation = current_layer[\"activation_function\"]\n",
    "            self.model.add(tf.keras.layers.Dense(\n",
    "                current_number_of_neurons, \n",
    "                input_shape = (self.input_size,),\n",
    "                activation = current_activation, \n",
    "                use_bias=True,\n",
    "                bias_initializer=tf.keras.initializers.Constant(1.0)\n",
    "            ))\n",
    "        for i in range(len(initial_weights)):\n",
    "            number_of_neurons = layers[i][\"number_of_neurons\"]\n",
    "            self.model.layers[i].set_weights([self.initial_weights[i], tf.ones((number_of_neurons,),dtype=tf.float32)])\n",
    "        # self.model.layers[0].set_weights([self.initial_weights])\n",
    "\n",
    "    def train_step(self, inputs, targets):\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=self.learning_rate)\n",
    "        print(self.model.layers[-1].activation)\n",
    "        loss_function = tf.keras.losses.CategoricalCrossentropy() if self.model.layers[-1].activation == tf.keras.activations.softmax else tf.keras.losses.MeanSquaredError()\n",
    "        print(f\"Ini loss_function : {loss_function}\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(inputs, training=True)\n",
    "            loss = loss_function(targets, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    def show_prediction(self):\n",
    "        print(\"========================================\")\n",
    "        print(\"Model layers:\", self.model.layers)\n",
    "        updated_weight = self.model.layers[0].get_weights()\n",
    "        print(\"Updated weights:\\n\", updated_weight)\n",
    "        print(\"=========================================\")\n",
    "\n",
    "    def predict(self, max_iteration):\n",
    "        for i in range(max_iteration):\n",
    "            for inputs_batch, targets_batch in self.dataset:\n",
    "                loss = self.train_step(inputs_batch, targets_batch)\n",
    "            print(f'Iteration {i+1}, Loss: {loss.numpy()}')\n",
    "\n",
    "        self.show_prediction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1, 0.2], [-0.3, 0.5], [0.4, 0.5]], [[0.2, 0.1], [0.4, -0.5], [0.7, 0.8]]]\n",
      "ini inputs :  [[-1.0, 0.2], [0.2, -1.0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer dense_53 weight shape (2, 2) is not compatible with provided weight shape (3, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     model \u001b[38;5;241m=\u001b[39m TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n\u001b[0;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mpredict(max_iter)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m initial_weights \u001b[38;5;241m=\u001b[39m json_file\u001b[38;5;241m.\u001b[39minitial_weights\n\u001b[0;32m     15\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m json_file\u001b[38;5;241m.\u001b[39mmax_iteration\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTensorFlowModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(max_iter)\n",
      "Cell \u001b[1;32mIn[54], line 27\u001b[0m, in \u001b[0;36mTensorFlowModel.__init__\u001b[1;34m(self, inputs, targets, learning_rate, batch_size, initial_weights, layers)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(initial_weights)):\n\u001b[0;32m     26\u001b[0m     number_of_neurons \u001b[38;5;241m=\u001b[39m layers[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_neurons\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:664\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layer_weights, weights):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    665\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weight shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    666\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not compatible with provided weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    667\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    668\u001b[0m         )\n\u001b[0;32m    669\u001b[0m     variable\u001b[38;5;241m.\u001b[39massign(value)\n",
      "\u001b[1;31mValueError\u001b[0m: Layer dense_53 weight shape (2, 2) is not compatible with provided weight shape (3, 2)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    currDir = os.getcwd()\n",
    "    testDir = currDir.replace(\"src\",\"test\")\n",
    "    file = os.path.join(testDir, \"mlp.json\")\n",
    "    json_file = JsonModelParser(file)\n",
    "    inputs = json_file.input\n",
    "    print(\"ini inputs : \", inputs)\n",
    "    targets = json_file.target\n",
    "    learning_rate = json_file.learning_rate\n",
    "    layers = json_file.layers\n",
    "    batch_size = json_file.batch_size\n",
    "    initial_weights = json_file.initial_weights\n",
    "    max_iter = json_file.max_iteration\n",
    "    model = TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n",
    "    model.predict(max_iter)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Outputs:\n",
      "[[ 1.7         2.1         0.90000004]\n",
      " [ 1.9000001   1.7        -0.19999993]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the inputs and targets\n",
    "inputs = tf.constant([\n",
    "    [3.0, 1.0],\n",
    "    [1.0, 2.0]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "targets = tf.constant([\n",
    "    [2.0, 0.3, -1.9],\n",
    "    [1.3, -0.7, 0.1]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Number of neurons, activation, and learning rate\n",
    "number_of_neurons = 3\n",
    "activation = \"linear\"\n",
    "learning_rate = 0.1\n",
    "batch_size = 2  # as you mentioned, batch_size of 2\n",
    "\n",
    "# Initial weights and new uniform bias of 1\n",
    "initial_weights = [\n",
    "    [0.1, 0.3, 0.2],  # weights for inputs to neuron 1\n",
    "    [0.4, 0.2, -0.7]  # weights for inputs to neuron 2\n",
    "]\n",
    "initial_bias = [1.0, 1.0, 1.0]  # uniform bias for all neurons\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(number_of_neurons, activation=activation, input_shape=(2,), use_bias=True)\n",
    "])\n",
    "\n",
    "# Set the initial weights and bias\n",
    "model.layers[0].set_weights([tf.constant(initial_weights, dtype=tf.float32), tf.constant(initial_bias, dtype=tf.float32)])\n",
    "\n",
    "# Compile the model with the specified optimizer and learning rate\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Since this is a simple forward pass, we'll use predict instead of fit to demonstrate batching\n",
    "outputs = model.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "print(\"Outputs:\")\n",
    "print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
