{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonModelParser:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = self.load_json_file()\n",
    "        self.parse_model_data()\n",
    "\n",
    "    def printDetails(self):\n",
    "        print(\"\\tINPUT SIZE:\",self.input_size)\n",
    "        print(\"\\tLAYERS:\", self.layers)\n",
    "        print(\"\\tINPUT:\", self.input)\n",
    "        print(\"\\tINITIAL WEIGHTS:\", self.initial_weights)\n",
    "        print(\"\\tTARGET:\", self.target)\n",
    "        print(\"\\tLEARNING RATE:\", self.learning_rate)\n",
    "        print(\"\\tBATCH SIZE:\", self.batch_size)\n",
    "        print(\"\\tMAX ITERATION:\", self.max_iteration)\n",
    "        print(\"\\tERROR THRESHOLD:\", self.error_threshold)\n",
    "    \n",
    "\n",
    "    def load_json_file(self):\n",
    "        try:\n",
    "            with open(self.filepath, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"The file {self.filepath} was not found\")\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error decoding JSON from the file {self.filepath}\")\n",
    "            return None\n",
    "\n",
    "    def parse_model_data(self):\n",
    "        if self.data:\n",
    "            self.case = self.data.get('case', {})\n",
    "            self.model = self.case.get('model', {})\n",
    "            self.input_size = self.model.get('input_size')\n",
    "\n",
    "            raw_layers = self.model.get('layers', [])   \n",
    "            self.layers = [{'number_of_neurons': layer.get('number_of_neurons'),\n",
    "                        'activation_function': layer.get('activation_function')}\n",
    "                       for layer in raw_layers]\n",
    "            \n",
    "            self.input = self.case.get('input', [])\n",
    "            print(self.case.get(\"initial_weights\"))\n",
    "            self.initial_weights = self.case.get('initial_weights', [])\n",
    "            self.target = self.case.get('target', [])\n",
    "            self.parameters = self.case.get('learning_parameters', {})\n",
    "\n",
    "            self.learning_rate = self.parameters.get('learning_rate')\n",
    "            self.batch_size = self.parameters.get('batch_size')\n",
    "            self.max_iteration = self.parameters.get('max_iteration')\n",
    "            self.error_threshold = self.parameters.get('error_threshold')\n",
    "\n",
    "            self.expect = self.data.get('expect', {})\n",
    "            self.stopped_by = self.expect.get('stopped_by', '')\n",
    "            self.final_weights = self.expect.get('final_weights', [])\n",
    "\n",
    "    @staticmethod\n",
    "    def save_json_file(data, filepath):\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as file:\n",
    "                json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        except IOError:\n",
    "            print(f\"Could not save data to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TensorFlowModel: \n",
    "    def __init__(self, inputs, targets, learning_rate, batch_size, initial_weights, layers) -> None:\n",
    "        self.inputs = tf.constant(inputs, dtype=tf.float32)\n",
    "        self.targets = tf.constant(targets, dtype=tf.float32)\n",
    "        self.initial_weights = tf.constant(initial_weights, dtype=tf.float32)\n",
    "        self.input_size = len(inputs[0])\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.inputs, self.targets))\n",
    "        self.dataset = self.dataset.batch(batch_size)\n",
    "        self.model = tf.keras.Sequential()\n",
    "        for i in range(len(layers)):\n",
    "            current_layer = layers[i]\n",
    "            current_number_of_neurons = current_layer[\"number_of_neurons\"]\n",
    "            current_activation = current_layer[\"activation_function\"]\n",
    "            self.model.add(tf.keras.layers.Dense(\n",
    "                current_number_of_neurons, \n",
    "                input_shape = (self.input_size,),\n",
    "                activation = current_activation, \n",
    "                use_bias = False\n",
    "            ))\n",
    "        for i in range(len(initial_weights)):\n",
    "            self.model.layers[i].set_weights([self.initial_weights[i]])\n",
    "        # self.model.layers[0].set_weights([self.initial_weights])\n",
    "\n",
    "    def train_step(self, inputs, targets):\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=self.learning_rate)\n",
    "        print(self.model.layers[-1].activation)\n",
    "        loss_function = tf.keras.losses.CategoricalCrossentropy() if self.model.layers[-1].activation == tf.keras.activations.softmax else tf.keras.losses.MeanSquaredError()\n",
    "        print(f\"Ini loss_function : {loss_function}\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(inputs, training=True)\n",
    "            loss = loss_function(targets, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    def show_prediction(self):\n",
    "        print(\"========================================\")\n",
    "        print(\"Model layers:\", self.model.layers)\n",
    "        updated_weight = self.model.layers[0].get_weights()\n",
    "        print(\"Updated weights:\\n\", updated_weight)\n",
    "        print(\"=========================================\")\n",
    "\n",
    "    def predict(self, max_iteration):\n",
    "        for i in range(max_iteration):\n",
    "            for inputs_batch, targets_batch in self.dataset:\n",
    "                loss = self.train_step(inputs_batch, targets_batch)\n",
    "            print(f'Iteration {i+1}, Loss: {loss.numpy()}')\n",
    "\n",
    "        self.show_prediction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.1, 0.9, -0.1], [-0.2, 0.8, 0.2], [0.3, -0.7, 0.3], [0.4, 0.6, -0.4], [0.5, 0.5, 0.5], [-0.6, 0.4, 0.6], [-0.7, -0.3, 0.7], [0.8, 0.2, -0.8], [0.9, -0.1, 0.0]]]\n",
      "ini inputs :  [[1, -2.4, -2.78, -0.6, 0.37, 2.46, -0.92, 2.76, 2.62], [1, -1.79, 1.65, -0.77, -1.03, 0.1, 2.12, -2.36, 1.25], [1, 1.65, 2.34, 0.27, 2.34, 0.52, 1.37, 1.77, 0.62]]\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD65A090>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD64B750>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD574750>\n",
      "Iteration 1, Loss: 1.3741796016693115\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD3F6710>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD589D90>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD447510>\n",
      "Iteration 2, Loss: 1.1949015855789185\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB88F6D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD60BB50>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD573D10>\n",
      "Iteration 3, Loss: 1.038373589515686\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD4647D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD648310>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD514D10>\n",
      "Iteration 4, Loss: 0.9036142230033875\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD57E710>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD629790>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB8858D0>\n",
      "Iteration 5, Loss: 0.7888412475585938\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB8858D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB8858D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD60BB50>\n",
      "Iteration 6, Loss: 0.6917867064476013\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD579790>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD587F90>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB886410>\n",
      "Iteration 7, Loss: 0.610023558139801\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD50C710>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD12AED0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD578810>\n",
      "Iteration 8, Loss: 0.5412096381187439\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD3B19D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD1CBD10>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD507950>\n",
      "Iteration 9, Loss: 0.48323050141334534\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD121390>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BB88F6D0>\n",
      "<function softmax at 0x000002A6B5B6A2A0>\n",
      "Ini loss_function : <keras.src.losses.losses.CategoricalCrossentropy object at 0x000002A6BD3D60D0>\n",
      "Iteration 10, Loss: 0.4342549443244934\n",
      "========================================\n",
      "Model layers: [<Dense name=dense_94, built=True>]\n",
      "Updated weights:\n",
      " [array([[ 0.12674606,  0.9149538 , -0.14169984],\n",
      "       [-0.33551654,  0.6770049 ,  0.45851156],\n",
      "       [ 0.48314434, -0.8524122 ,  0.26926783],\n",
      "       [ 0.34002548,  0.5723754 , -0.31240082],\n",
      "       [ 0.31397712,  0.4634974 ,  0.7225255 ],\n",
      "       [-0.69652444,  0.47891888,  0.6176055 ],\n",
      "       [-0.50884515, -0.36354133,  0.57238674],\n",
      "       [ 0.41891316,  0.26354513, -0.48245814],\n",
      "       [ 0.9037415 , -0.01759502, -0.08614664]], dtype=float32)]\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    currDir = os.getcwd()\n",
    "    testDir = currDir.replace(\"src\",\"test\")\n",
    "    file = os.path.join(testDir, \"softmax.json\")\n",
    "    json_file = JsonModelParser(file)\n",
    "    inputs = json_file.input\n",
    "    inputs = [[1] + sub_array for sub_array in json_file.input]\n",
    "    print(\"ini inputs : \", inputs)\n",
    "    targets = json_file.target\n",
    "    learning_rate = json_file.learning_rate\n",
    "    layers = json_file.layers\n",
    "    batch_size = json_file.batch_size\n",
    "    initial_weights = json_file.initial_weights\n",
    "    max_iter = json_file.max_iteration\n",
    "    model = TensorFlowModel(inputs, targets, learning_rate, batch_size, initial_weights, layers)\n",
    "    model.predict(max_iter)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Outputs:\n",
      "[[ 1.7         2.1         0.90000004]\n",
      " [ 1.9000001   1.7        -0.19999993]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the inputs and targets\n",
    "inputs = tf.constant([\n",
    "    [3.0, 1.0],\n",
    "    [1.0, 2.0]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "targets = tf.constant([\n",
    "    [2.0, 0.3, -1.9],\n",
    "    [1.3, -0.7, 0.1]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Number of neurons, activation, and learning rate\n",
    "number_of_neurons = 3\n",
    "activation = \"linear\"\n",
    "learning_rate = 0.1\n",
    "batch_size = 2  # as you mentioned, batch_size of 2\n",
    "\n",
    "# Initial weights and new uniform bias of 1\n",
    "initial_weights = [\n",
    "    [0.1, 0.3, 0.2],  # weights for inputs to neuron 1\n",
    "    [0.4, 0.2, -0.7]  # weights for inputs to neuron 2\n",
    "]\n",
    "initial_bias = [1.0, 1.0, 1.0]  # uniform bias for all neurons\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(number_of_neurons, activation=activation, input_shape=(2,), use_bias=True)\n",
    "])\n",
    "\n",
    "# Set the initial weights and bias\n",
    "model.layers[0].set_weights([tf.constant(initial_weights, dtype=tf.float32), tf.constant(initial_bias, dtype=tf.float32)])\n",
    "\n",
    "# Compile the model with the specified optimizer and learning rate\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Since this is a simple forward pass, we'll use predict instead of fit to demonstrate batching\n",
    "outputs = model.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "print(\"Outputs:\")\n",
    "print(outputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
